// This code was generated by Berp (https://github.com/gasparnagy/berp/).
//
// Changes to this file may cause incorrect behavior and will be lost if
// the code is regenerated.
@using Berp;
@helper FormatEnumName(String enumName)
{
    @(
        // format enum names the way they are formatted in Rust (PascalCase): "EOF" is converted to "Eof"
        System.Text.RegularExpressions.Regex.Replace(
            enumName.Replace("#", "").Replace("_", ""),
            "(?<=[A-Z])[A-Z]",
            m => m.Value.ToLower()
        )
    )
}
@helper FormatMethodName(String methodName)
{
    @(
        // format method names the way they are formatted in Rust (snake_case): "EOF" is converted to "eof"
        System.Text.RegularExpressions.Regex.Replace(
            methodName.Replace("#", ""),
            "(?<=[a-z0-9])[A-Z]", m => "_" + m.Value
        ).ToLowerInvariant()
    )
}
@helper CallProduction(ProductionRule production)
{
    switch(production.Type) {
        case ProductionRuleType.Start:
            @:self.start_rule(context, RuleType::@production.RuleName.Replace("_", ""))?;
            break;
        case ProductionRuleType.End:
            @:self.end_rule(context, RuleType::@production.RuleName.Replace("_", ""))?;
            break;
        case ProductionRuleType.Process:
            @:self.build(context, token)?;
            break;
    }
}
@helper HandleParserError(IEnumerable<string> expectedTokens, State state)
{<text>
        #[cfg_attr(rustfmt, rustfmt_skip)] // because the generated lengths differ
        let state_comment = String::from("State: @state.Id - @Raw(state.Comment)");

        token.borrow().detach();

        #[cfg_attr(rustfmt, rustfmt_skip)] // because the generated lengths differ
        let expected_tokens: Vec<String> = vec![
            @foreach(var expectedToken in expectedTokens) {<text>            String::from("@expectedToken"),
</text>}
        ];

        let token = token.borrow();
        let token_location = token.location.expect("token location");

        let error = if token.is_eof() {
            Error::UnexpectedEof {
                location: token_location,
                state_comment,
                expected_tokens,
            }
        } else {
            let location = if token_location.get_column() > 1 {
                token_location
            } else {
                let token_line = token.line.as_ref().expect("token line");
                let line = token_location.get_line();
                let column = token_line.indent() + 1;
                Location::new(line, column)
            };

            Error::UnexpectedToken {
                location,
                state_comment,
                received_token: Box::new(token.clone()),
                expected_tokens,
            }
        };

        if self.stop_at_first_error {
            return Err(error);
        }

        self.add_error(context, error);
        Ok(@state.Id)
</text>}
@helper MatchToken(TokenType tokenType)
{<text>match_@(FormatMethodName(tokenType.Name))(context, &mut *token.borrow_mut())</text>}

use std::cell::RefCell;
use std::collections::VecDeque;
use std::default::Default;
use std::fmt;
use std::io::Read;
use std::rc::Rc;
use std::sync::Arc;

use ast::Location;
use ast_builder::AstBuilder;
use error::{Error, Result};
use gherkin_dialect::GherkinDialect;
use token::Token;
use token_matcher::TokenMatcher;
use token_scanner::TokenScanner;

#[derive(Debug, PartialEq, Eq, Hash, Clone, Copy)]
pub enum TokenType {
    None,
    @foreach(var rule in Model.RuleSet.TokenRules) {
<text>    @FormatEnumName(rule.Name),
</text>}
}

impl fmt::Display for TokenType {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{:?}", self)
    }
}

#[derive(Debug, PartialEq, Eq, Hash, Clone, Copy)]
#[cfg_attr(rustfmt, rustfmt_skip)] // simplifies the parser template
pub enum RuleType {
    None,
    @foreach(var rule in Model.RuleSet.Where(r => !r.TempRule)) {
<text>    @FormatEnumName(rule.Name), // @rule.ToString(true)
</text>}
}

impl fmt::Display for RuleType {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{:?}", self)
    }
}

impl From<TokenType> for RuleType {
    fn from(token_type: TokenType) -> RuleType {
        match token_type {
        @foreach(var rule in Model.RuleSet.TokenRules) {
<text>            TokenType::@(FormatEnumName(rule.Name)) => RuleType::@(FormatEnumName(rule.Name)),
</text>}
            _ => RuleType::Other,
        }
    }
}

pub struct @(Model.ParserClassName)<B: Builder> {
    builder: B,
    token_match: Box<TokenMatch>,
    stop_at_first_error: bool,
}

impl Default for @(Model.ParserClassName)<AstBuilder> {
    fn default() -> @(Model.ParserClassName)<AstBuilder> {
        @(Model.ParserClassName)Options::new().create()
    }
}

pub struct @(Model.ParserClassName)Options<B: Builder> {
    builder: B,
    token_match: Option<Box<TokenMatch>>,
    stop_at_first_error: Option<bool>,
}

impl Default for @(Model.ParserClassName)Options<AstBuilder> {
    fn default() -> @(Model.ParserClassName)Options<AstBuilder> {
        @(Model.ParserClassName)Options {
            builder: AstBuilder::default(),
            token_match: None,
            stop_at_first_error: None,
        }
    }
}

impl @(Model.ParserClassName)Options<AstBuilder> {
    pub fn new() -> ParserOptions<AstBuilder> {
        @(Model.ParserClassName)Options::default()
    }
}

impl<B: Builder> @(Model.ParserClassName)Options<B> {
    pub fn with_builder(builder: B) -> @(Model.ParserClassName)Options<B> {
        ParserOptions {
            builder,
            token_match: None,
            stop_at_first_error: None,
        }
    }
}

impl<B: Builder> @(Model.ParserClassName)Options<B> {
    pub fn language<S>(self, language: S) -> @(Model.ParserClassName)Options<B>
    where
        S: Into<String>,
    {
        self.token_matcher(TokenMatcher::with_default_dialect_name(language))
    }

    pub fn dialect_provider<DP>(self, dialect_provider: DP) -> @(Model.ParserClassName)Options<B>
    where
        DP: GherkinDialectProvide + 'static,
    {
        self.token_matcher(TokenMatcher::with_dialect_provider(dialect_provider))
    }

    pub(crate) fn token_matcher<TM>(mut self, token_match: TM) -> @(Model.ParserClassName)Options<B>
    where
        TM: TokenMatch + 'static,
    {
        self.token_match = Some(Box::new(token_match));
        self
    }

    pub fn stop_at_first_error(mut self, stop_at_first_error: bool) -> @(Model.ParserClassName)Options<B> {
        self.stop_at_first_error = Some(stop_at_first_error);
        self
    }

    pub fn create(self) -> Parser<B> {
        @(Model.ParserClassName) {
            builder: self.builder,
            token_match: self
                .token_match
                .unwrap_or_else(|| Box::new(TokenMatcher::default())),
            stop_at_first_error: self.stop_at_first_error.unwrap_or(false),
        }
    }
}

struct @(Model.ParserClassName)Context<'a> {
    token_scan: &'a mut TokenScan,
    token_queue: VecDeque<Rc<RefCell<Token>>>,
    errors: Vec<Error>,
}

impl<B: Builder> @(Model.ParserClassName)<B> {
    pub fn with_builder(builder: B) -> @(Model.ParserClassName)<B> {
        ParserOptions::with_builder(builder).create()
    }

    pub fn parse_str<S: AsRef<str>>(&mut self, source: S) -> Result<B::BuilderResult> {
        self.parse(&mut TokenScanner::from(source.as_ref()))
    }

    pub fn parse_reader<R: Read>(&mut self, source: R) -> Result<B::BuilderResult> {
        self.parse(&mut TokenScanner::from(source))
    }

    fn parse<TS: TokenScan>(&mut self, token_scan: &mut TS) -> Result<B::BuilderResult> {
        self.builder.reset();
        self.token_match.reset();

        let mut context = ParserContext {
            token_scan,
            token_queue: VecDeque::new(),
            errors: Vec::new(),
        };

        self.start_rule(&mut context, RuleType::@Model.RuleSet.StartRule.Name)?;
        let mut state: u32 = 0;
        let mut token: Rc<RefCell<Token>>;
        loop {
            match self.read_token(&mut context) {
                Ok(t) => token = t,
                Err(error) => {
                    self.add_error(&mut context, error);
                    if self.stop_at_first_error {
                        break;
                    }
                    continue;
                }
            };
            state = self.match_token(state, token.clone(), &mut context)?;

            if token.borrow().is_eof() {
                break;
            }
        }

        self.end_rule(&mut context, RuleType::@Model.RuleSet.StartRule.Name)?;

        if !context.errors.is_empty() {
            Err(Error::Composite(context.errors))?;
        }

        Ok(self.builder.get_result())
    }

    fn add_error(&mut self, context: &mut ParserContext, error: Error) {
        context.errors.push(error);
        // if (context.errors.size() > 10)
        //     throw new ParserException.CompositeParserException(context.errors);
    }

    fn handle_ast_result(&mut self, context: &mut ParserContext, result: Result<()>) -> Result<()> {
        self.handle_external_result(context, result, ())
    }

    fn handle_external_result<V>(
        &mut self,
        context: &mut ParserContext,
        result: Result<V>,
        default_value: V,
    ) -> Result<V> {
        if self.stop_at_first_error {
            return result;
        }

        match result {
            Ok(value) => return Ok(value),
            Err(error) => match error {
                Error::Composite(errors) => {
                    for parse_error in errors {
                        self.add_error(context, parse_error);
                    }
                }
                _ => self.add_error(context, error),
            },
        }

        Ok(default_value)
    }

    fn build(&mut self, context: &mut ParserContext, token: Rc<RefCell<Token>>) -> Result<()> {
        let result = self.builder.build(token);
        self.handle_ast_result(context, result)
    }

    fn start_rule(&mut self, context: &mut ParserContext, rule_type: RuleType) -> Result<()> {
        let result = self.builder.start_rule(rule_type);
        self.handle_ast_result(context, result)
    }

    fn end_rule(&mut self, context: &mut ParserContext, rule_type: RuleType) -> Result<()> {
        let result = self.builder.end_rule(rule_type);
        self.handle_ast_result(context, result)
    }

    fn read_token(&mut self, context: &mut ParserContext) -> Result<Rc<RefCell<Token>>> {
        match context.token_queue.pop_front() {
            Some(token) => Ok(token),
            None => context
                .token_scan
                .next()
                .map(|token| Rc::new(RefCell::new(token))),
        }
    }
@foreach(var rule in Model.RuleSet.TokenRules)
{<text>
    #[cfg_attr(rustfmt, rustfmt_skip)] // because the generated lengths differ
    fn match_@(FormatMethodName(rule.Name))(
        &mut self,
        context: &mut ParserContext,
        token: &mut Token,
    ) -> Result<bool> {
        @if (rule.Name != "#EOF")
        {
        <text>if token.is_eof() {
            return Ok(false);
        };</text>
        }
        let result = self.token_match.match_@(FormatMethodName(rule.Name))(token);
        self.handle_external_result(context, result, false)
    }</text>
}

    fn match_token(
        &mut self,
        state: u32,
        token: Rc<RefCell<Token>>,
        context: &mut ParserContext,
    ) -> Result<u32> {
        match state {
        @foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
        {
            @:@state.Id => self.match_token_at_@(state.Id)(token, context),
        }
            _ => panic!("Unknown state: {}", state),
        }
    }
@foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
{
<text>
    // @Raw(state.Comment)
    fn match_token_at_@(state.Id)(
        &mut self,
        token: Rc<RefCell<Token>>,
        context: &mut ParserContext,
    ) -> Result<u32> {
</text>foreach(var transition in state.Transitions)
        {
        if (transition.LookAheadHint == null) {
        @:if self.@MatchToken(transition.TokenType)? {
        } else {
        <text>let match_@(FormatMethodName(transition.TokenType.Name))_with_lookahead = {
            // Workaround for borrow checking
            let mut token_borrow = token.borrow_mut();
            self.match_@(FormatMethodName(transition.TokenType.Name))(context, &mut token_borrow)?
                && self.lookahead_@(transition.LookAheadHint.Id)(context, &token_borrow)
        };
        if match_@(FormatMethodName(transition.TokenType.Name))_with_lookahead {</text>
        }
            foreach(var production in transition.Productions) {
                @CallProduction(production)
            }
        @:    return Ok(@transition.TargetState);
        @:}
        }
        @HandleParserError(state.Transitions.Select(t => "#" + t.TokenType.ToString()).Distinct(), state)
    @:}
}
@foreach(var lookAheadHint in Model.RuleSet.LookAheadHints)
{
<text>
    #[allow(unknown_lints, nonminimal_bool)] // simplifies the parser template
    #[cfg_attr(rustfmt, rustfmt_skip)] // simplifies the parser template
    fn lookahead_@(lookAheadHint.Id)(&mut self, context: &mut ParserContext, current_token: &Token) -> bool {
        current_token.detach();
        let mut token: Rc<RefCell<Token>>;
        let mut queue: VecDeque<Rc<RefCell<Token>>> = VecDeque::new();
        let mut found_match = false;
        loop {
            token = self.read_token(context).expect("read next token");
            token.borrow().detach();
            queue.push_back(token.clone());

            if false
            @foreach(var tokenType in lookAheadHint.ExpectedTokens)
            {
                @:|| self.@MatchToken(tokenType) .unwrap_or(false)
            }
            {
                found_match = true;
                break;
            }

             if true
             @foreach(var tokenType in lookAheadHint.Skip)
{                 @:&& !self.@MatchToken(tokenType) .unwrap_or(true)
             }             {
                 break;
             }
        }

        context.token_queue.extend(queue);

        found_match
    }</text>
}
}

pub trait Builder {
    type BuilderResult;

    fn build(&mut self, token: Rc<RefCell<Token>>) -> Result<()>;
    fn start_rule(&mut self, rule_type: RuleType) -> Result<()>;
    fn end_rule(&mut self, rule_type: RuleType) -> Result<()>;
    fn get_result(&mut self) -> Self::BuilderResult;
    fn reset(&mut self);
}

pub trait TokenScan {
    fn next(&mut self) -> Result<Token>;
}

pub trait TokenMatch {
    @foreach(var rule in Model.RuleSet.TokenRules)
    {
    @:fn match_@(FormatMethodName(rule.Name))(&mut self, token: &mut Token) -> Result<bool>;
    }
    fn reset(&mut self);
}

pub trait GherkinDialectProvide {
    fn get_default_dialect(&self) -> Result<Arc<GherkinDialect>>;

    fn get_dialect(&self, language: &str, location: Location) -> Result<Arc<GherkinDialect>>;

    fn get_languages(&self) -> Vec<&String>;
}
