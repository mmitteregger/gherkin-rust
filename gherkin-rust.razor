//      This code was generated by Berp (http://https://github.com/gasparnagy/berp/).
//
//      Changes to this file may cause incorrect behavior and will be lost if
//      the code is regenerated.
@using Berp;
@helper FormatEnumName(String enumName)
{
    @(
        // format enum names the way they are formatted in Rust (PascalCase): "EOF" is converted to "Eof"
        System.Text.RegularExpressions.Regex.Replace(
            enumName.Replace("#", "").Replace("_", ""),
            "(?<=[A-Z])[A-Z]",
            m => m.Value.ToLower()
        )
    )
}
@helper FormatMethodName(String methodName)
{
    @(
        // format method names the way they are formatted in Rust (snake_case): "EOF" is converted to "eof"
        System.Text.RegularExpressions.Regex.Replace(
            methodName.Replace("#", ""),
            "(?<=[a-z0-9])[A-Z]", m => "_" + m.Value
        ).ToLowerInvariant()
    )
}
@helper CallProduction(ProductionRule production)
{
    switch(production.Type) {
        case ProductionRuleType.Start:
            @:self.start_rule(context, RuleType::@production.RuleName.Replace("_", ""))?;
            break;
        case ProductionRuleType.End:
            @:self.end_rule(context, RuleType::@production.RuleName.Replace("_", ""))?;
            break;
        case ProductionRuleType.Process:
            @:self.build(context, token)?;
            break;
    }
}
@helper HandleParserError(IEnumerable<string> expectedTokens, State state)
{<text>
        let state_comment = String::from("State: @state.Id - @Raw(state.Comment)");
        token.borrow().detach();
        let expected_tokens: Vec<String> = vec![
            @foreach(var expectedToken in expectedTokens) {<text>            String::from("@expectedToken"),
</text>}
        ];

        let token = token.borrow();
        let token_location = token.location.expect("token location");

        let error = if token.is_eof() {
            Error::UnexpectedEof {
                location: token_location,
                state_comment,
                expected_tokens,
            }
        } else {
            let location = if token_location.get_column() > 1 {
                token_location
            } else {
                let token_line = token.line.as_ref().expect("token line");
                let line = token_location.get_line();
                let column = token_line.indent() + 1;
                Location::new(line, column)
            };

            Error::UnexpectedToken {
                location,
                state_comment,
                received_token: Box::new(token.clone()),
                expected_tokens,
            }
        };

        if self.stop_at_first_error {
            return Err(error);
        }

        self.add_error(context, error);
        Ok(@state.Id)
</text>}
@helper MatchToken(TokenType tokenType)
{<text>match_@(FormatMethodName(tokenType.Name))(context, &mut *token.borrow_mut())</text>}

use std::io::prelude::*;
use std::collections::VecDeque;
use std::fmt;
use std::default::Default;
use std::rc::Rc;
use std::sync::Arc;
use std::cell::RefCell;

use error::{Result, Error};
use ast::Location;
use token::Token;
use gherkin_dialect::GherkinDialect;
use ast_builder::AstBuilder;
use token_matcher::TokenMatcher;
use token_scanner::TokenScanner;

#[derive(Debug, PartialEq, Eq, Hash, Clone, Copy)]
pub enum TokenType {
    None,
    @foreach(var rule in Model.RuleSet.TokenRules) {
<text>    @FormatEnumName(rule.Name),
</text>}
}

impl fmt::Display for TokenType {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{:?}", self)
    }
}

#[derive(Debug, PartialEq, Eq, Hash, Clone, Copy)]
pub enum RuleType {
    None,
    @foreach(var rule in Model.RuleSet.Where(r => !r.TempRule)) {
<text>    @FormatEnumName(rule.Name), // @rule.ToString(true)
</text>}
}

impl fmt::Display for RuleType {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{:?}", self)
    }
}

impl From<TokenType> for RuleType {
    fn from(token_type: TokenType) -> RuleType {
        match token_type {
        @foreach(var rule in Model.RuleSet.TokenRules) {
<text>            TokenType::@(FormatEnumName(rule.Name)) => RuleType::@(FormatEnumName(rule.Name)),
</text>}
            _ => RuleType::Other,
        }
    }
}

struct ParserContext<'a> {
    token_scanner: &'a mut TokenScan,
    token_matcher: &'a mut TokenMatch,
    token_queue: VecDeque<Rc<RefCell<Token>>>,
    errors: Vec<Error>,
}

pub struct @Model.ParserClassName<B: Builder> {
    builder: B,
    pub stop_at_first_error: bool,
}

impl Default for @Model.ParserClassName<AstBuilder> {
    fn default() -> @Model.ParserClassName<AstBuilder> {
        @Model.ParserClassName::with_builder(AstBuilder::default())
    }
}

impl<B: Builder> @Model.ParserClassName<B> {
    pub fn with_builder(builder: B) -> @Model.ParserClassName<B> {
        Parser {
            builder,
            stop_at_first_error: false,
        }
    }

    pub fn parse_str(&mut self, source: &str) -> Result<B::BuilderResult> {
        self.parse_reader(source.as_bytes())
    }

    pub fn parse_reader<R>(&mut self, source: R) -> Result<B::BuilderResult> where R: Read {
        self.parse_tokens(&mut TokenScanner::from(source))
    }

    pub fn parse_tokens<TS>(&mut self, token_scanner: &mut TS) -> Result<B::BuilderResult> where TS: TokenScan {
        self.parse_tokens_with_token_matcher(token_scanner, &mut TokenMatcher::default())
    }

    pub fn parse_str_with_token_matcher<TM>(&mut self, source: &str, token_matcher: &mut TM)
            -> Result<B::BuilderResult> where TM: TokenMatch {
        self.parse_reader_with_token_matcher(source.as_bytes(), token_matcher)
    }

    pub fn parse_reader_with_token_matcher<R, TM>(&mut self, source: R, token_matcher: &mut TM)
            -> Result<B::BuilderResult> where R: Read, TM: TokenMatch {
        self.parse_tokens_with_token_matcher(&mut TokenScanner::from(source), token_matcher)
    }

    pub fn parse_tokens_with_token_matcher<TS, TM>(&mut self, token_scanner: &mut TS, token_matcher: &mut TM)
            -> Result<B::BuilderResult> where TS: TokenScan, TM: TokenMatch {
        self.builder.reset();
        token_matcher.reset();

        let mut context = ParserContext {
                token_scanner,
                token_matcher,
                token_queue: VecDeque::new(),
                errors: Vec::new(),
        };

        self.start_rule(&mut context, RuleType::@Model.RuleSet.StartRule.Name)?;
        let mut state: u32 = 0;
        let mut token: Rc<RefCell<Token>>;
        loop {
            match self.read_token(&mut context) {
                Ok(t) => token = t,
                Err(error) => {
                    self.add_error(&mut context, error);
                    if self.stop_at_first_error {
                        break;
                    }
                    continue;
                },
            };
            state = self.match_token(state, token.clone(), &mut context)?;

            if token.borrow().is_eof() {
                break;
            }
        }

        self.end_rule(&mut context, RuleType::@Model.RuleSet.StartRule.Name)?;

        if !context.errors.is_empty() {
            Err(Error::Composite(context.errors))?;
        }

        Ok(self.builder.get_result())
    }

    fn add_error(&mut self, context: &mut ParserContext, error: Error) {
        context.errors.push(error);
//        if (context.errors.size() > 10)
//            throw new ParserException.CompositeParserException(context.errors);
    }

    fn handle_ast_result(&mut self, context: &mut ParserContext, result: Result<()>) -> Result<()> {
        self.handle_external_result(context, result, ())
    }

    #[allow(unused)] // until the function is implemented
    fn handle_external_result<V>(&mut self, context: &mut ParserContext, result: Result<V>, default_value: V)
            -> Result<V> {

        if self.stop_at_first_error {
            return result;
        }

        match result {
            Ok(value) => return Ok(value),
            Err(error) => {
                match error {
                    Error::Composite(errors) => {
                        for parse_error in errors {
                            self.add_error(context, parse_error);
                        }
                    },
                    _ => self.add_error(context, error),
                }
            },
        }

        Ok(default_value)
    }

    fn build(&mut self, context: &mut ParserContext, token: Rc<RefCell<Token>>) -> Result<()> {
        let result = self.builder.build(token);
        self.handle_ast_result(context, result)
    }

    fn start_rule(&mut self, context: &mut ParserContext, rule_type: RuleType) -> Result<()> {
        let result = self.builder.start_rule(rule_type);
        self.handle_ast_result(context, result)
    }

    fn end_rule(&mut self, context: &mut ParserContext, rule_type: RuleType) -> Result<()> {
        let result = self.builder.end_rule(rule_type);
        self.handle_ast_result(context, result)
    }

    fn read_token(&mut self, context: &mut ParserContext) -> Result<Rc<RefCell<Token>>> {
        match context.token_queue.pop_front() {
            Some(token) => Ok(token),
            None => context.token_scanner.scan_next_token().map(|token| Rc::new(RefCell::new(token))),
        }
    }
@foreach(var rule in Model.RuleSet.TokenRules)
{<text>
    fn match_@(FormatMethodName(rule.Name))(&mut self, context: &mut ParserContext, token: &mut Token) -> Result<bool> {
        @if (rule.Name != "#EOF")
        {
        @:if token.is_eof() {return Ok(false)};
        }
        let result = context.token_matcher.match_@(FormatMethodName(rule.Name))(token);
        self.handle_external_result(context, result, false)
    }</text>
}

    fn match_token(&mut self, state: u32, token: Rc<RefCell<Token>>, context: &mut ParserContext) -> Result<u32> {
        match state {
        @foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
        {
            @:@state.Id => self.match_token_at_@(state.Id)(token, context),
        }
            _ => panic!("Unknown state: {}", state),
        }
    }
@foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
{
<text>
    // @Raw(state.Comment)
    fn match_token_at_@(state.Id)(&mut self, token: Rc<RefCell<Token>>, context: &mut ParserContext) -> Result<u32> {
</text>foreach(var transition in state.Transitions)
        {
        if (transition.LookAheadHint == null) {
        @:if self.@MatchToken(transition.TokenType)? {
        } else {
        <text>let match_@(FormatMethodName(transition.TokenType.Name))_with_lookahead = {
            // Workaround for borrow checking
            let mut token_borrow = token.borrow_mut();
            self.match_@(FormatMethodName(transition.TokenType.Name))(context, &mut token_borrow)?
                && self.lookahead_@(transition.LookAheadHint.Id)(context, &token_borrow)
        };
        if match_@(FormatMethodName(transition.TokenType.Name))_with_lookahead {</text>
        }
            foreach(var production in transition.Productions) {
                @CallProduction(production)
            }
        @:    return Ok(@transition.TargetState);
        @:}
        }
        @HandleParserError(state.Transitions.Select(t => "#" + t.TokenType.ToString()).Distinct(), state)
    @:}
}
@foreach(var lookAheadHint in Model.RuleSet.LookAheadHints)
{
<text>
    fn lookahead_@(lookAheadHint.Id)(&mut self, context: &mut ParserContext, current_token: &Token) -> bool {
        current_token.detach();
        let mut token: Rc<RefCell<Token>>;
        let mut queue: VecDeque<Rc<RefCell<Token>>> = VecDeque::new();
        let mut found_match = false;
        loop {
            token = self.read_token(context).expect("read next token");
            token.borrow().detach();
            queue.push_back(token.clone());

            if false
            @foreach(var tokenType in lookAheadHint.ExpectedTokens)
            {
                @:|| self.@MatchToken(tokenType) .unwrap_or(false)
            }
            {
                found_match = true;
                break;
            }

             if true
             @foreach(var tokenType in lookAheadHint.Skip)
{                 @:&& !self.@MatchToken(tokenType) .unwrap_or(true)
             }             {
                 break;
             }
        }

        context.token_queue.extend(queue);

        found_match
    }</text>
}
}

pub trait Builder {
    type BuilderResult;

    fn build(&mut self, token: Rc<RefCell<Token>>) -> Result<()>;
    fn start_rule(&mut self, rule_type: RuleType) -> Result<()>;
    fn end_rule(&mut self, rule_type: RuleType) -> Result<()>;
    fn get_result(&mut self) -> Self::BuilderResult;
    fn reset(&mut self);
}

pub trait TokenScan {
    fn scan_next_token(&mut self) -> Result<Token>;
}

pub trait TokenMatch {
    @foreach(var rule in Model.RuleSet.TokenRules)
    {
    @:fn match_@(FormatMethodName(rule.Name))(&mut self, token: &mut Token) -> Result<bool>;
    }
    fn reset(&mut self);
}

pub trait GherkinDialectProvide {
    fn get_default_dialect(&self) -> Result<Arc<GherkinDialect>>;

    fn get_dialect(&self, language: &str, location: Location) -> Result<Arc<GherkinDialect>>;

    fn get_languages(&self) -> Vec<&String>;
}
